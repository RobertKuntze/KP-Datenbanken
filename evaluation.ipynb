{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import shlex\n",
    "import subprocess\n",
    "import platform\n",
    "from docker import from_env as docker_client\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from configparser import ConfigParser\n",
    "\n",
    "import pandas as pd\n",
    "import psycopg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading config\n",
    "def load_config(filename=\"database.ini\", section=\"postgresql\"):\n",
    "    parser = ConfigParser()\n",
    "    parser.read(filename)\n",
    "\n",
    "    config = {}\n",
    "    if parser.has_section(section):\n",
    "        params = parser.items(section)\n",
    "        for param in params:\n",
    "            config[param[0]] = param[1]\n",
    "    else:\n",
    "        raise Exception(\"Section {0} not found in the {1} file\".format(section, filename))\n",
    "    return config\n",
    "\n",
    "#connecting to db\n",
    "def connect():\n",
    "    try:\n",
    "        pg_conn = psycopg.connect(**load_config(), connect_timeout = 5)\n",
    "        return pg_conn\n",
    "    except psycopg.DatabaseError as error:\n",
    "        raise error\n",
    "\n",
    "#disconnecting from db\n",
    "def disconnect(pg_conn, cursor = None):\n",
    "    if cursor != None:\n",
    "        cursor.close()\n",
    "    pg_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restart db and remove cache if possible\n",
    "def restart_db():\n",
    "    env = load_config(section = \"docker\")\n",
    "\n",
    "    if env[\"container_name\"] != \"\":\n",
    "        try:\n",
    "            client = docker_client()\n",
    "            container = client.containers.get(env[\"container_name\"])\n",
    "\n",
    "            container.stop()\n",
    "            container.wait()\n",
    "            container.start()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    elif platform.system() == \"Linux\":\n",
    "        try:\n",
    "            subprocess.run(['sudo', 'systemctl', 'stop', 'postgresql'], check=True)\n",
    "\n",
    "            subprocess.run([\"sync\"], check=True)\n",
    "            subprocess.run([\"sudo\", \"sh\", \"-c\", \"echo 3 > /proc/sys/vm/drop_caches\"], check=True)\n",
    "            \n",
    "            subprocess.run(['sudo', 'systemctl', 'start', 'postgresql'], check=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"System configuration not supported\")\n",
    "\n",
    "#wait for db to accept connections\n",
    "def wait_for_db(timeout = 15):\n",
    "    start = time.time()\n",
    "\n",
    "    while time.time() - start < timeout:\n",
    "        try:\n",
    "            pg_conn = connect()\n",
    "            cursor = pg_conn.cursor()\n",
    "\n",
    "            disconnect(pg_conn, cursor)\n",
    "            return\n",
    "        except psycopg.OperationalError:\n",
    "            time.sleep(1)\n",
    "    raise TimeoutError(\"Could not connect to the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Query:\n",
    "    label: str\n",
    "    string: str\n",
    "    groups: list[str]\n",
    "\n",
    "#formatting query\n",
    "def format_query(query):\n",
    "    #removing comments\n",
    "    query = re.sub(r\"--.*\", \"\", query)\n",
    "    query = re.sub(r\"/\\*.*?\\*/\", \"\", query, flags = re.DOTALL)\n",
    "    query = re.sub(r\"EXPLAIN (ANALYZE|(\\(.*\\)))\", \"\", query) #fallback for explain\n",
    "    \n",
    "    #joining words with spaces while preserving quoted strings\n",
    "    query = \" \".join(shlex.split(query, posix = False))\n",
    "\n",
    "    return query\n",
    "\n",
    "queries: list[Query] = []\n",
    "\n",
    "#loading all queries\n",
    "for root, dirs, files in os.walk(os.curdir):\n",
    "    for file in files:\n",
    "        if not file.endswith(\".sql\"):\n",
    "            continue\n",
    "\n",
    "        path = os.path.join(root, file)\n",
    "        \n",
    "        query = open(path, \"r\").read()\n",
    "        query = format_query(query)\n",
    "\n",
    "        groups = root.removeprefix(\".\").removeprefix(os.sep).split(os.sep)\n",
    "\n",
    "        query = Query(file, query, groups)\n",
    "\n",
    "        queries.append(query)\n",
    "        print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class QueryResult:\n",
    "    label: str\n",
    "    groups: list[str]\n",
    "    query: str\n",
    "    bench_time: datetime\n",
    "    result_set: dict\n",
    "    exec_time: float\n",
    "\n",
    "#executes given query and returns QueryResult object\n",
    "def run_query(query, cursor, analyze_prefix = \"\"):\n",
    "\n",
    "    bench_start, query_start = datetime.now(), time.perf_counter_ns()\n",
    "    cursor.execute(analyze_prefix + query.string)\n",
    "\n",
    "    result_set = cursor.fetchall()\n",
    "    query_end = time.perf_counter_ns()\n",
    "\n",
    "    result = QueryResult(\n",
    "        label = query.label,\n",
    "        groups = query.groups,\n",
    "        query = query.string,\n",
    "        bench_time = bench_start,\n",
    "        result_set = json.dumps(result_set),\n",
    "        exec_time = query_end - query_start\n",
    "    )\n",
    "\n",
    "    return result\n",
    "\n",
    "#executes query with precaching and returns list of results\n",
    "def hot_run_query(query, precache_repeats = 3, query_repeats = 1, analyze_prefix = \"\"):\n",
    "    \n",
    "    results: list[QueryResult] = []\n",
    "\n",
    "    pg_conn = connect()\n",
    "    cursor = pg_conn.cursor()\n",
    "    \n",
    "    for statement in query.string.split(\";\"):\n",
    "        statement = statement.strip()\n",
    "\n",
    "        if statement == \"\":\n",
    "            continue\n",
    "\n",
    "        if statement.upper().startswith((\"CREATE\", \"REPLACE\", \"REFRESH\", \"DROP\")):\n",
    "            cursor.execute(statement)\n",
    "            continue\n",
    "\n",
    "        for _ in range(precache_repeats):\n",
    "            cursor.execute(statement)\n",
    "        \n",
    "        new_query = Query(query.label, statement, query.groups)\n",
    "\n",
    "        for _ in range(query_repeats):\n",
    "            result = run_query(new_query, cursor, analyze_prefix)\n",
    "            results.append(result)\n",
    "\n",
    "    disconnect(pg_conn, cursor)\n",
    "\n",
    "    return results\n",
    "\n",
    "#executes query without precaching and returns list of results\n",
    "def cold_run_query(query, query_repeats = 1, analyze_prefix = \"\"):\n",
    "\n",
    "    results: list[QueryResult] = []\n",
    "    \n",
    "    for _ in range(query_repeats):\n",
    "\n",
    "        restart_db()\n",
    "        wait_for_db()\n",
    "\n",
    "        pg_conn = connect()\n",
    "        cursor = pg_conn.cursor()\n",
    "\n",
    "        for statement in query.string.split(\";\"):\n",
    "            statement = statement.strip()\n",
    "\n",
    "            if statement == \"\":\n",
    "                continue\n",
    "\n",
    "            if statement.upper().startswith((\"CREATE\", \"REPLACE\", \"REFRESH\", \"DROP\")):\n",
    "                cursor.execute(statement)\n",
    "                continue\n",
    "\n",
    "            new_query = Query(query.label, statement, query.groups)\n",
    "            \n",
    "            result = run_query(new_query, cursor, analyze_prefix)\n",
    "            results.append(result)\n",
    "\n",
    "        disconnect(pg_conn, cursor)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execution settings\n",
    "analyze_prefix = \"EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON, SETTINGS) \"\n",
    "only_run = [] #full label or group name\n",
    "precache_repeats = 3\n",
    "query_repeats = 10\n",
    "cold_run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executing queries\n",
    "results: list[QueryResult] = []\n",
    "\n",
    "for query in queries:\n",
    "\n",
    "    if (\n",
    "        len(only_run) > 0\n",
    "        and query.label not in only_run\n",
    "        and not any(i in only_run for i in query.groups)\n",
    "    ):\n",
    "        continue\n",
    "\n",
    "    print(query.label)\n",
    "\n",
    "    if cold_run:\n",
    "        result = cold_run_query(query, query_repeats, analyze_prefix)\n",
    "    else:\n",
    "        result = hot_run_query(query, precache_repeats, query_repeats, analyze_prefix)\n",
    "\n",
    "    results.extend(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving results\n",
    "file_name = \"results\"\n",
    "\n",
    "if cold_run:\n",
    "    file_name += \"_cold\"\n",
    "else:\n",
    "    file_name += \"_hot\"\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(file_name + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting results\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_palette(\"viridis\")\n",
    "sns.set_theme(style = \"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"results.csv\")\n",
    "\n",
    "def getTotalCost(text):\n",
    "    match = re.search(r'\"Total Cost\": (\\d+)', text)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "df[\"Total Cost\"] = df[\"result_set\"].apply(getTotalCost)\n",
    "\n",
    "df[\"Cost per Time\"] = df[\"Total Cost\"]/df[\"exec_time\"]\n",
    "df[\"Time per Cost\"] = df[\"exec_time\"]/df[\"Total Cost\"]\n",
    "\n",
    "df[\"Json\"] = \"json\" in df[\"label\"]\n",
    "\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.regplot(\n",
    "    data = df,\n",
    "    x = \"Total Cost\",\n",
    "    y = \"exec_time\",\n",
    "    scatter = True,\n",
    "    \n",
    ")\n",
    "\n",
    "g.set(\n",
    "    title = \"Runtime per Cost\",\n",
    "    xlabel = \"Total Cost\",\n",
    "    ylabel = \"Runtime\"\n",
    ")\n",
    "\n",
    "g.get_figure().set_size_inches(6, 6)\n",
    "g.get_figure().tight_layout()\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.regplot(\n",
    "    data = df,\n",
    "    x = \"exec_time\",\n",
    "    y = \"Time per Cost\",\n",
    "    scatter = True,\n",
    ")\n",
    "\n",
    "g.set(\n",
    "    title = \"Time per Cost to Runtime\",\n",
    "    xlabel = \"Runtime\",\n",
    "    ylabel = \"Cost per Runtime\"\n",
    ")\n",
    "\n",
    "g.get_figure().set_size_inches(6, 6)\n",
    "g.get_figure().tight_layout()\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.regplot(\n",
    "    data = df,\n",
    "    x = \"Total Cost\",\n",
    "    y = \"Time per Cost\",\n",
    "    scatter = True,\n",
    ")\n",
    "\n",
    "g.set(\n",
    "    title = \"Time per Cost to Total Cost\",\n",
    "    xlabel = \"Total Cost\",\n",
    "    ylabel = \"Time per Cost\"\n",
    ")\n",
    "\n",
    "g.get_figure().set_size_inches(6, 6)\n",
    "g.get_figure().tight_layout()\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lmplot(\n",
    "    data = df,\n",
    "    x = \"Total Cost\",\n",
    "    y = \"Time per Cost\",\n",
    "    hue = \"label\",\n",
    ")\n",
    "\n",
    "g.set(\n",
    "    title = \"Time per Cost to Total Cost\",\n",
    "    xlabel = \"Total Cost\",\n",
    "    ylabel = \"Time per Cost\"\n",
    ")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"results.csv\")\n",
    "\n",
    "df[\"exec_time\"] = df[\"exec_time\"] / 1000000\n",
    "\n",
    "g = sns.barplot(\n",
    "    data = df,\n",
    "    x = \"exec_time\",\n",
    "    y = \"label\"\n",
    ")\n",
    "\n",
    "g.set(\n",
    "    title = \"Query runtimes\",\n",
    "    xlabel = \"Execution time [ms]\",\n",
    "    ylabel = \"Query\"\n",
    ")\n",
    "\n",
    "g.get_figure().set_size_inches(10, 10)\n",
    "g.get_figure().tight_layout()\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
